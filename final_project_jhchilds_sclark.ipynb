{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Privacy Final Project\n",
    "### Sam Clark & Josh Childs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we've decided to compare the accuracy of several normal Convolutional Neural Networks to their counter parts that will use differential privacy. We will be using the MNIST dataset with the tensflow library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pickle\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.distributions import Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(28, kernel_size=(3,3), input_shape=input_shape),\n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  Flatten(),\n",
    "  Dense(128, activation=tf.nn.relu),  \n",
    "  Dropout(0.3),\n",
    "  Dense(10,activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "# model.compile(optimizer='sgd',\n",
    "#               loss='sparse_categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x=x_train,y=y_train, epochs=1, callbacks = [callback])\n",
    "# model.save(\"models/original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Privacy Optimizer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_l2_clip(v, b):\n",
    "    norm = tf.norm(v, ord=2)\n",
    "    return tf.cond(norm > b, lambda: b * (v / norm), lambda: v)\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def tf_laplace_mech(v, sensitivity, epsilon):\n",
    "    return tf.numpy_function(laplace_mech, [v, sensitivity, epsilon], tf.float32)\n",
    "\n",
    "def tf_gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def tf_gaussian_mech_RDP(v, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)\n",
    "\n",
    "def tf_gaussian_mech_zCDP(v, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, epochs, b=3.0, learning_rate=0.01, name=\"DPOptimizer\", **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        self.epochs = epochs\n",
    "        self.b = b\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        pass\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "        }\n",
    "\n",
    "    \n",
    "class EpsilonDeltaDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, epsilon, delta, b=3.0, learning_rate=0.01, name=\"EpsilonDeltaDPGradientDescent\", **kwargs):\n",
    "        DPOptimizer.__init__(self, epochs, b=b, learning_rate=learning_rate, name=name, **kwargs)        \n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_i = self.epsilon / self.epochs\n",
    "        delta_i = self.delta / self.epochs\n",
    "        \n",
    "        #clipped_grad = tf.math.reduce_mean(tf_l2_clip(grad, self.b), axis=0, keepdims=True)\n",
    "        #clipped_grad = tf.numpy_function(lambda x: np.mean(x, axis=0), [tf_l2_clip(grad, self.b)], tf.float32)\n",
    "        #clipped_grad = tf.math.reduce_mean(tf.clip_by_norm(grad, self.b), axis=0)\n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech(clipped_grad, self.b/len(x_train), epsilon_i, delta_i) * lr_t\n",
    "        #new_var_m = var - grad * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)\n",
    "\n",
    "    \n",
    "class RenyiDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, alpha, epsilon_bar, b=3.0, learning_rate=0.01, name=\"RenyiDPGradientDescent\", **kwargs):\n",
    "        super().__init__(epochs,b=b, learning_rate=learning_rate, name=name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        \n",
    "        self.epsilon_bar = epsilon_bar\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_bar_i = self.epsilon_bar / self.epochs\n",
    "         \n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech_RDP(clipped_grad, self.b/len(x_train), self.alpha, epsilon_bar_i) * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)\n",
    "\n",
    "        \n",
    "class ZeroConcentratedDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, rho, b=3.0, learning_rate=0.01, name=\"ZeroConcentratedDPGradientDescent\", **kwargs):\n",
    "        super().__init__(epochs,b=b, learning_rate=learning_rate, name=name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        \n",
    "        self.rho = rho\n",
    "        \n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        rho_i = self.rho / self.epochs\n",
    "         \n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech_zCDP(clipped_grad, self.b/len(x_train), rho_i) * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)\n",
    "        \n",
    "class PureDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, epsilon, b=3.0, learning_rate=0.01, name=\"PureDPGradientDescent\", **kwargs):\n",
    "        super().__init__(epochs,b=b, learning_rate=learning_rate, name=name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        \n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_i = self.epsilon / self.epochs\n",
    "         \n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_laplace_mech(clipped_grad, self.b/len(x_train), epsilon_i) * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es = callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "# ed_dp = EpsilonDeltaDPGradientDescent(epochs=3, epsilon=0.1, delta=1e-5)\n",
    "# r_dp = RenyiDPGradientDescent(epochs=1, alpha=500, epsilon_bar=0.001)\n",
    "# zc_dp = ZeroConcentratedDPGradientDescent(epochs=5, rho=0.000001)\n",
    "# pure_dp = PureDPGradientDescent(epochs=1, epsilon=.001)\n",
    "\n",
    "# # we need to create new layers, otherwise scuffed\n",
    "# model = Sequential([\n",
    "#   Conv2D(28, kernel_size=(3,3), input_shape=input_shape),\n",
    "#   MaxPooling2D(pool_size=(2, 2)),\n",
    "#   Flatten(),\n",
    "#   Dense(128, activation=tf.nn.relu),  \n",
    "#   Dropout(0.3),\n",
    "#   Dense(10,activation=tf.nn.softmax)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer=pure_dp, \n",
    "#               loss='sparse_categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x=x_train,y=y_train, epochs=1, callbacks=[es], batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Noise on Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.linspace(0.0000001, 0.0001, 100)\n",
    "\n",
    "epsilons = []\n",
    "for rho in rhos:\n",
    "    epsilon = rho + 2 * np.sqrt(rho * np.log(1 / 1e-5))\n",
    "    epsilons.append(epsilon)\n",
    "\n",
    "epsilon_bars = []\n",
    "for epsilon in epsilons:\n",
    "    epsilon_bar = epsilon - np.log(1 / 1e-5) / (5 - 1)\n",
    "    epsilon_bars.append(epsilon_bar)\n",
    "\n",
    "ep_de_opts = [EpsilonDeltaDPGradientDescent(epochs=10, epsilon=e, delta=1e-5) for e in epsilons]\n",
    "renyi_opts = [RenyiDPGradientDescent(epochs=10, alpha=5, epsilon_bar=e_b) for e_b in epsilon_bars]\n",
    "zeroc_opts = [ZeroConcentratedDPGradientDescent(epochs=10, rho=r) for r in rhos]\n",
    "pured_opts = [PureDPGradientDescent(epochs=10, epsilon=e) for e in epsilons]\n",
    "\n",
    "optimizer_data = {\n",
    "    \"EpsilonDelta\": {\n",
    "        \"batches\" : ep_de_opts,\n",
    "        \"accuracy\": []\n",
    "    },\n",
    "    \"Renyi\": {\n",
    "        \"batches\" : renyi_opts,\n",
    "        \"accuracy\": []\n",
    "    },\n",
    "    \"ZeroConc\": {\n",
    "        \"batches\" : zeroc_opts,\n",
    "        \"accuracy\": []\n",
    "    },\n",
    "    \"Pure\": {\n",
    "        \"batches\": pured_opts,\n",
    "        \"accuracy\": []\n",
    "    }\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.1391 - accuracy: 0.4317\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.1051 - accuracy: 0.3485\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.2702 - accuracy: 0.2618\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.3578 - accuracy: 0.1851\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4129 - accuracy: 0.1344\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4412 - accuracy: 0.1116\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4339 - accuracy: 0.0979\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4843 - accuracy: 0.1002\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4845 - accuracy: 0.1077\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 2.4949 - accuracy: 0.1047\n",
      "313/313 [==============================] - 0s 671us/step - loss: 2.4604 - accuracy: 0.1035\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.8766 - accuracy: 0.7225\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6128 - accuracy: 0.8081\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.5984 - accuracy: 0.8145\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6083 - accuracy: 0.8124\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6177 - accuracy: 0.8102\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6231 - accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6306 - accuracy: 0.8039\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6235 - accuracy: 0.8067\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6447 - accuracy: 0.8030\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.6437 - accuracy: 0.8066\n",
      "313/313 [==============================] - 0s 651us/step - loss: 0.4157 - accuracy: 0.8710\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.8434 - accuracy: 0.7450\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4893 - accuracy: 0.8471\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4646 - accuracy: 0.8575\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4761 - accuracy: 0.8546\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4665 - accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4622 - accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4678 - accuracy: 0.8589\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4702 - accuracy: 0.8578\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4742 - accuracy: 0.8530\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4689 - accuracy: 0.8588\n",
      "313/313 [==============================] - 0s 648us/step - loss: 0.2795 - accuracy: 0.9192\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7634 - accuracy: 0.7694\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4479 - accuracy: 0.8614\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4181 - accuracy: 0.8699\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8798\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8819\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3833 - accuracy: 0.8825\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8814\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3845 - accuracy: 0.8815\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3794 - accuracy: 0.8839\n",
      "313/313 [==============================] - 0s 659us/step - loss: 0.2232 - accuracy: 0.9341\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7733 - accuracy: 0.7735\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.4135 - accuracy: 0.8721\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3784 - accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3640 - accuracy: 0.8876\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3547 - accuracy: 0.8911\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.8936\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3444 - accuracy: 0.8935\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8952\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8946\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8945\n",
      "313/313 [==============================] - 0s 704us/step - loss: 0.2116 - accuracy: 0.9355\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7263 - accuracy: 0.7891\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3977 - accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.8936\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3334 - accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3208 - accuracy: 0.9014\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3224 - accuracy: 0.9011\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3151 - accuracy: 0.9034\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3177 - accuracy: 0.9029\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.9043\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3124 - accuracy: 0.9035\n",
      "313/313 [==============================] - 0s 628us/step - loss: 0.1935 - accuracy: 0.9406\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7569 - accuracy: 0.7813\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3840 - accuracy: 0.8834\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3418 - accuracy: 0.8951\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3183 - accuracy: 0.9024\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3155 - accuracy: 0.9045\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3113 - accuracy: 0.9047\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3044 - accuracy: 0.9059\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.9089\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2917 - accuracy: 0.9099\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2925 - accuracy: 0.9096\n",
      "313/313 [==============================] - 0s 649us/step - loss: 0.1823 - accuracy: 0.9432\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7818 - accuracy: 0.7780: 0s - loss: 0.9067 - ac\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3820 - accuracy: 0.8849\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3423 - accuracy: 0.8952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3167 - accuracy: 0.9021\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2985 - accuracy: 0.9091\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2949 - accuracy: 0.9102\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2830 - accuracy: 0.9122\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2795 - accuracy: 0.9137\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2826 - accuracy: 0.9124\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.9149\n",
      "313/313 [==============================] - 0s 671us/step - loss: 0.1694 - accuracy: 0.9487\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7377 - accuracy: 0.7864\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3738 - accuracy: 0.8875\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3271 - accuracy: 0.9002\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3015 - accuracy: 0.9082\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2935 - accuracy: 0.9093\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2786 - accuracy: 0.9157\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2744 - accuracy: 0.9157\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2665 - accuracy: 0.9196\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2589 - accuracy: 0.9209\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2597 - accuracy: 0.9207\n",
      "313/313 [==============================] - 0s 637us/step - loss: 0.1616 - accuracy: 0.9535\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7924 - accuracy: 0.7738\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3680 - accuracy: 0.8874\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3224 - accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2988 - accuracy: 0.9077\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2820 - accuracy: 0.9126\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2715 - accuracy: 0.9173\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2603 - accuracy: 0.9193\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2553 - accuracy: 0.9227\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2489 - accuracy: 0.9244\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2447 - accuracy: 0.9256\n",
      "313/313 [==============================] - 0s 639us/step - loss: 0.1595 - accuracy: 0.9513\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7531 - accuracy: 0.7863\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8879\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3153 - accuracy: 0.9050\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2873 - accuracy: 0.9113\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2728 - accuracy: 0.9172\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2605 - accuracy: 0.9199\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.2608 - accuracy: 0.9206\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2524 - accuracy: 0.9234\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2480 - accuracy: 0.9255\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2439 - accuracy: 0.9247\n",
      "313/313 [==============================] - 0s 661us/step - loss: 0.1561 - accuracy: 0.9539\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.8034 - accuracy: 0.7665\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3676 - accuracy: 0.8874\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3093 - accuracy: 0.9046\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2825 - accuracy: 0.9142\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2670 - accuracy: 0.9180\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2560 - accuracy: 0.9207\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2494 - accuracy: 0.9234\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2437 - accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2407 - accuracy: 0.9252\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.2324 - accuracy: 0.9284\n",
      "313/313 [==============================] - 0s 646us/step - loss: 0.1433 - accuracy: 0.9530\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.7250 - accuracy: 0.7902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8905\n",
      "Epoch 3/10\n",
      "593/938 [=================>............] - ETA: 0s - loss: 0.3163 - accuracy: 0.9045"
     ]
    }
   ],
   "source": [
    "for opt in optimizer_data:\n",
    "    for batch in optimizer_data[opt][\"batches\"]:\n",
    "\n",
    "        model = Sequential([\n",
    "          Conv2D(28, kernel_size=(3,3), input_shape=input_shape),\n",
    "          MaxPooling2D(pool_size=(2, 2)),\n",
    "          Flatten(),\n",
    "          Dense(128, activation=tf.nn.relu),  \n",
    "          Dropout(0.3),\n",
    "          Dense(10,activation=tf.nn.softmax)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=batch, \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        model.fit(x=x_train,y=y_train, epochs=10, batch_size=64)\n",
    "        accuracy = model.evaluate(x_test, y_test)\n",
    "        optimizer_data[opt][\"accuracy\"].append(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(optimizer_data, open(\"optimizer_data.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_RDP_gaussian_mech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-1f9dde6f2754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf_RDP_gaussian_mech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf_RDP_gaussian_mech' is not defined"
     ]
    }
   ],
   "source": [
    "t = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "tf_RDP_gaussian_mech(t, 0.0001, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1.0002027 , 0.99996525, 1.0000987 , 1.0000061 ], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "tf_gaussian_mech_zCDP(t, 0.0001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 115.59105 ,  316.6945  , -122.92863 ,  -63.800293], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "tf_gaussian_mech_RDP(t, 1.0, 5, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_mean(t, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 1s 885us/step - loss: 2.1672 - accuracy: 0.2213\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1s 886us/step - loss: 2.0692 - accuracy: 0.3365\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1s 907us/step - loss: 2.0478 - accuracy: 0.3722\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1s 888us/step - loss: 2.0401 - accuracy: 0.38310s - loss: 2.0412 - \n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1s 879us/step - loss: 2.0350 - accuracy: 0.3899\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1s 867us/step - loss: 2.0305 - accuracy: 0.3949\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1s 942us/step - loss: 2.0261 - accuracy: 0.4008\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1s 882us/step - loss: 2.0215 - accuracy: 0.4049\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1s 899us/step - loss: 2.0168 - accuracy: 0.4092\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1s 920us/step - loss: 2.0120 - accuracy: 0.4118\n",
      "313/313 [==============================] - 0s 644us/step - loss: 2.0088 - accuracy: 0.4125\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Flatten(input_shape=(28, 28, 1)),\n",
    "  Dense(128, activation='relu'),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=EpsilonDeltaDPGradientDescent(epochs=10, epsilon=10000000.0, delta=1e-5),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train,y=y_train, epochs=10, batch_size=64)\n",
    "accuracy = model.evaluate(x_test, y_test)\n",
    "optimizer_data[opt][\"accuracy\"].append(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
