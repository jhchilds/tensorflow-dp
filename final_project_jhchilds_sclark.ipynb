{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Privacy Final Project\n",
    "### Sam Clark & Josh Childs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we've decided to compare the accuracy of several normal Convolutional Neural Networks to their counter parts that will use differential privacy. We will be using the MNIST dataset with the tensflow library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(28, kernel_size=(3,3), input_shape=input_shape),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),  \n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "# model.compile(optimizer='sgd',\n",
    "#               loss='sparse_categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x=x_train,y=y_train, epochs=1, callbacks = [callback])\n",
    "# model.save(\"models/original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Privacy Optimizer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_l2_clip(v, b):\n",
    "    norm = tf.norm(v, ord=2)\n",
    "    return tf.cond(norm > b, lambda: b * (v / norm), lambda: v)\n",
    "\n",
    "\n",
    "def tf_gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def tf_gaussian_mech_RDP(v, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)\n",
    "\n",
    "def tf_gaussian_mech_zCDP(v, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, epochs, b=3.0, learning_rate=0.01, name=\"DPOptimizer\", **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        self.epochs = epochs\n",
    "        self.b = b\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        pass\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "        }\n",
    "\n",
    "    \n",
    "class EpsilonDeltaDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, epsilon, delta, b=3.0, learning_rate=0.01, name=\"EpsilonDeltaDPGradientDescent\", **kwargs):\n",
    "        DPOptimizer.__init__(self, epochs, b=b, learning_rate=learning_rate, name=name, **kwargs)        \n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_i = self.epsilon / self.epochs\n",
    "        print(self.epochs)\n",
    "        delta_i = self.delta / self.epochs\n",
    "        print(delta_i)\n",
    "        \n",
    "        #clipped_grad = tf.math.reduce_mean(tf_l2_clip(grad, self.b), axis=0)\n",
    "        #clipped_grad = tf.numpy_function(lambda x: np.mean(x, axis=0), [tf_l2_clip(grad, self.b)], tf.float32)\n",
    "        #clipped_grad = tf.math.reduce_mean(tf.clip_by_norm(grad, self.b), axis=0)\n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech(clipped_grad, self.b/len(x_train), epsilon_i, delta_i) * lr_t\n",
    "        #new_var_m = var - grad * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)\n",
    "\n",
    "    \n",
    "class RenyiDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, alpha, epsilon_bar, b=3.0, learning_rate=0.01, name=\"RenyiDPGradientDescent\", **kwargs):\n",
    "        super().__init__(epochs,b=b, learning_rate=learning_rate, name=name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        \n",
    "        self.epsilon_bar = epsilon_bar\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_bar_i = self.epsilon_bar / self.epochs\n",
    "         \n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech_RDP(clipped_grad, self.b/len(x_train), self.alpha, epsilon_bar_i) * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)\n",
    "\n",
    "        \n",
    "class ZeroConcentratedDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, rho, b=3.0, learning_rate=0.01, name=\"ZeroConcentratedDPGradientDescent\", **kwargs):\n",
    "        super().__init__(epochs,b=b, learning_rate=learning_rate, name=name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        \n",
    "        self.rho = rho\n",
    "        \n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        rho_i = self.rho / self.epochs\n",
    "         \n",
    "        clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech_zCDP(clipped_grad, self.b/len(x_train), rho_i) * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 14s 15ms/step - loss: 0.7842 - accuracy: 0.7753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x166b41040>"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "ed_dp = EpsilonDeltaDPGradientDescent(1, 1000, 1e-5)\n",
    "r_dp = RenyiDPGradientDescent(1, 500, 0.001)\n",
    "zc_dp = ZeroConcentratedDPGradientDescent(5, 0.000001)\n",
    "model.compile(optimizer=zc_dp, \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train,y=y_train, epochs=1, callbacks=[es], batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.9289808, 1.0607969, 0.9809418, 0.9453022], dtype=float32)>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "tf_RDP_gaussian_mech(t, 0.0001, 500, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.99968153, 1.000329  , 1.0001874 , 1.0001769 ], dtype=float32)>"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "tf_gaussian_mech_zCDP(t, 0.0001, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
