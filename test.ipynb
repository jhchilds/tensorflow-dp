{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('https://github.com/jnear/cs211-data-privacy/raw/master/homework/adult_with_pii.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "x_train = X[:training_size]\n",
    "x_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([1 if int(val) == 1 else 0 for val in y_test])\n",
    "y_train = np.array([1 if int(val) == 1 else 0 for val in y_train])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_l2_clip(v, b):\n",
    "    norm = tf.norm(v, ord=2)\n",
    "    return tf.cond(norm > b, lambda: b * (v / norm), lambda: v)\n",
    "\n",
    "def laplace_mech(v, sensitivity, epsilon):\n",
    "    return v + np.random.laplace(loc=0, scale=sensitivity / epsilon)\n",
    "\n",
    "def tf_laplace_mech(v, sensitivity, epsilon):\n",
    "    return tf.numpy_function(laplace_mech, [v, sensitivity, epsilon], tf.float32)\n",
    "\n",
    "def tf_gaussian_mech(v, sensitivity, epsilon, delta):\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sensitivity * np.sqrt(2*np.log(1.25/delta)) / epsilon)\n",
    "\n",
    "def tf_gaussian_mech_RDP(v, sensitivity, alpha, epsilon):\n",
    "    sigma = np.sqrt((sensitivity**2 * alpha) / (2 * epsilon))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)\n",
    "\n",
    "def tf_gaussian_mech_zCDP(v, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return v + tf.random.normal(v.shape, mean=0.0, stddev=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOptimizer(tf.keras.optimizers.Optimizer):\n",
    "    def __init__(self, epochs, b=3.0, learning_rate=0.01, name=\"DPOptimizer\", **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", learning_rate)\n",
    "        self.epochs = epochs\n",
    "        self.b = b\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        pass\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "        }\n",
    "\n",
    "    \n",
    "class EpsilonDeltaDPGradientDescent(DPOptimizer):\n",
    "    def __init__(self, epochs, epsilon, delta, b=3.0, learning_rate=0.01, name=\"EpsilonDeltaDPGradientDescent\", **kwargs):\n",
    "        DPOptimizer.__init__(self, epochs, b=b, learning_rate=learning_rate, name=name, **kwargs)        \n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)\n",
    "        \n",
    "        epsilon_i = self.epsilon / self.epochs\n",
    "        delta_i = self.delta / self.epochs\n",
    "        \n",
    "        clipped_grad = tf.math.reduce_mean(tf_l2_clip(grad, self.b), axis=0)\n",
    "        #clipped_grad = tf.numpy_function(lambda x: np.mean(x, axis=0), [tf_l2_clip(grad, self.b)], tf.float32)\n",
    "        #clipped_grad = tf.math.reduce_mean(tf.clip_by_norm(grad, self.b), axis=0)\n",
    "        #clipped_grad = tf_l2_clip(grad, self.b)\n",
    "        new_var_m = var - tf_gaussian_mech(clipped_grad, self.b/len(x_train), epsilon_i, delta_i) * lr_t\n",
    "        #new_var_m = var - grad * lr_t\n",
    "        \n",
    "        new_var = new_var_m\n",
    "        var.assign(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "566/566 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.7506\n",
      "Epoch 2/3\n",
      "566/566 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.7506\n",
      "Epoch 3/3\n",
      "566/566 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.7506\n",
      "283/283 [==============================] - 0s 636us/step - loss: nan - accuracy: 0.7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.7585139274597168]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(1024, input_shape=(X.shape[1],)),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1024),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1024),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(1),\n",
    "    layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=EpsilonDeltaDPGradientDescent(epochs=3, epsilon=0.1, delta=1e-5), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train,y=y_train, epochs=3, batch_size=64)\n",
    "accuracy = model.evaluate(x_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- joe's algorithm unmodified in example sort of falls off a cliff too\n",
    "- reduce mean works on adult dataset\n",
    "- reduce mean doesn't work on flattened mnist, so it's probably not dimensions issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
